{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc220136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4), # 4, 84, 84 -> 32, 20, 20\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2), # 64, 9, 9\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1), # 64, 7, 7\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 6),\n",
    "        )\n",
    "\n",
    "        self.__inititalize_weights()\n",
    "    \n",
    "    def __inititalize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / 255.0\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be76744",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m env = FrameStackObservation(env, stack_size=\u001b[32m4\u001b[39m)\n\u001b[32m     17\u001b[39m ddqn = DDQN(env, QNetwork, buffer_size=\u001b[32m100000\u001b[39m, batch_size=\u001b[32m32\u001b[39m,\n\u001b[32m     18\u001b[39m                     gamma=\u001b[32m0.99\u001b[39m, lr=\u001b[32m1e-4\u001b[39m, epsilon_start=\u001b[32m1.0\u001b[39m, \n\u001b[32m     19\u001b[39m                     epsilon_end=\u001b[32m0.01\u001b[39m, epsilon_decay=\u001b[32m0.995\u001b[39m,\n\u001b[32m     20\u001b[39m                     target_update_interval=\u001b[32m500\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m rewards, losses = \u001b[43mddqn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPISODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/Python/ReinforcementLearning/trainer.py:98\u001b[39m, in \u001b[36mDDQN.train\u001b[39m\u001b[34m(self, episodes, stats_interval)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m episode_over:\n\u001b[32m     97\u001b[39m     action = \u001b[38;5;28mself\u001b[39m.select_action(state)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     next_state, reward, terminated, truncated, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     episode_over = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[32m    101\u001b[39m     \u001b[38;5;28mself\u001b[39m.buffer.append((state, action, reward, next_state, episode_over))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/venvs/3.12/lib/python3.12/site-packages/gymnasium/wrappers/stateful_observation.py:425\u001b[39m, in \u001b[36mFrameStackObservation.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    415\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    416\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    417\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Steps through the environment, appending the observation to the frame buffer.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m    419\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m \u001b[33;03m        Stacked observations, reward, terminated, truncated, and info from the environment\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     obs, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.obs_queue.append(obs)\n\u001b[32m    428\u001b[39m     updated_obs = deepcopy(\n\u001b[32m    429\u001b[39m         concatenate(\u001b[38;5;28mself\u001b[39m.env.observation_space, \u001b[38;5;28mself\u001b[39m.obs_queue, \u001b[38;5;28mself\u001b[39m.stacked_obs)\n\u001b[32m    430\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/venvs/3.12/lib/python3.12/site-packages/gymnasium/core.py:560\u001b[39m, in \u001b[36mObservationWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    558\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    559\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observation(observation), reward, terminated, truncated, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/venvs/3.12/lib/python3.12/site-packages/gymnasium/core.py:561\u001b[39m, in \u001b[36mObservationWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[32m    560\u001b[39m observation, reward, terminated, truncated, info = \u001b[38;5;28mself\u001b[39m.env.step(action)\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m, reward, terminated, truncated, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/venvs/3.12/lib/python3.12/site-packages/gymnasium/wrappers/transform_observation.py:95\u001b[39m, in \u001b[36mTransformObservation.observation\u001b[39m\u001b[34m(self, observation)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobservation\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: ObsType) -> Any:\n\u001b[32m     94\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply function to the observation.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/venvs/3.12/lib/python3.12/site-packages/gymnasium/wrappers/transform_observation.py:331\u001b[39m, in \u001b[36mGrayscaleObservation.__init__.<locals>.<lambda>\u001b[39m\u001b[34m(obs)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    324\u001b[39m     new_observation_space = spaces.Box(\n\u001b[32m    325\u001b[39m         low=\u001b[32m0\u001b[39m, high=\u001b[32m255\u001b[39m, shape=env.observation_space.shape[:\u001b[32m2\u001b[39m], dtype=np.uint8\n\u001b[32m    326\u001b[39m     )\n\u001b[32m    327\u001b[39m     TransformObservation.\u001b[34m__init__\u001b[39m(\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    329\u001b[39m         env=env,\n\u001b[32m    330\u001b[39m         func=\u001b[38;5;28;01mlambda\u001b[39;00m obs: np.sum(\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m             \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.2125\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.7154\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0721\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, axis=-\u001b[32m1\u001b[39m\n\u001b[32m    332\u001b[39m         ).astype(np.uint8),\n\u001b[32m    333\u001b[39m         observation_space=new_observation_space,\n\u001b[32m    334\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from trainer import DDQN\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import FrameStackObservation, GrayscaleObservation, ResizeObservation\n",
    "import ale_py\n",
    "\n",
    "EPISODES = 2000\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "env = gym.make(\"ALE/Pong-v5\", render_mode=\"rgb_array\", frameskip=1)\n",
    "env = GrayscaleObservation(env)\n",
    "env = ResizeObservation(env, shape=(84,84))\n",
    "env = FrameStackObservation(env, stack_size=4)\n",
    "\n",
    "ddqn = DDQN(env, QNetwork, buffer_size=100000, batch_size=32,\n",
    "                    gamma=0.99, lr=1e-4, epsilon_start=1.0, \n",
    "                    epsilon_end=0.01, epsilon_decay=0.995,\n",
    "                    target_update_interval=500)\n",
    "rewards, losses = ddqn.train(episodes=EPISODES, stats_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c977c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
